{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import spacy\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# warnings imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = [\n",
    "'alt.atheism',\n",
    "'talk.religion.misc',\n",
    "'comp.graphics',\n",
    "'sci.space',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "#import dataset\n",
    "dataset = fetch_20newsgroups(subset='all', categories=categories,\n",
    "shuffle=True, random_state=42)\n",
    "#save labels\n",
    "labels = dataset.target\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3387 documents\n",
      "4 categories\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the unique labels\n",
    "true_k = np.unique(labels).shape[0]\n",
    "\n",
    "print(\"%d documents\" % len(dataset.data))\n",
    "print(\"%d categories\" % len(dataset.target_names))\n",
    "data = dataset.data\n",
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 3387, n_features: 24545\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english',\n",
    "use_idf=True)\n",
    "X = vectorizer.fit_transform(data)\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensionality Reduction\n",
    "# Vectorizer results are normalized, which makes KMeans behave better\n",
    "    # Since LSA/SVD results are not normalized, we have to redo the normalization.\n",
    "\n",
    "    #If we do not normalize the data, variables with different scaling \n",
    "    # will be weighted differently in the distance formula \n",
    "    # that is being optimized during training.\n",
    "    \n",
    "n_components = 5\n",
    "svd = TruncatedSVD(n_components)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "#The final X is the input which we will be using. \n",
    "# It has been cleaned, TF-IDF transformed, and its dimensions reduced.\n",
    "X = lsa.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with MiniBatchKMeans(batch_size=1000, init_size=1000, n_clusters=4, n_init=1)\n",
      "Cluster 0:\n",
      " henry\n",
      " space\n",
      " toronto\n",
      " access\n",
      " nasa\n",
      " digex\n",
      " com\n",
      " pat\n",
      " zoo\n",
      " alaska\n",
      "Cluster 1:\n",
      " graphics\n",
      " space\n",
      " image\n",
      " com\n",
      " nasa\n",
      " university\n",
      " posting\n",
      " program\n",
      " host\n",
      " images\n",
      "Cluster 2:\n",
      " god\n",
      " people\n",
      " com\n",
      " jesus\n",
      " don\n",
      " say\n",
      " believe\n",
      " think\n",
      " bible\n",
      " just\n",
      "Cluster 3:\n",
      " sgi\n",
      " livesey\n",
      " keith\n",
      " solntze\n",
      " wpd\n",
      " jon\n",
      " com\n",
      " caltech\n",
      " morality\n",
      " moral\n",
      "First method:\n",
      "Homogeneity: 0.558\n",
      "Completeness: 0.606\n",
      "V-measure: 0.581\n",
      "Adjusted Rand-Index: 0.555\n",
      "Silhouette Coefficient: 0.426 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=3, n_init=&#x27;auto&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=3, n_init=&#x27;auto&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=3, n_init='auto', random_state=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scikit-learn offers two implementations of kmeans:\n",
    "# either in mini-batches or without\n",
    "minibatch = True\n",
    "if minibatch:\n",
    "   km = MiniBatchKMeans(n_clusters=true_k, init='k-means++', n_init=1,\n",
    "   init_size=1000, batch_size=1000)\n",
    "else:\n",
    "   km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "km.fit(X)\n",
    "# top words per cluster\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "\n",
    "original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "for i in range(true_k):\n",
    "   print(\"Cluster %d:\" % i)\n",
    "   for ind in order_centroids[i, :10]:\n",
    "      print(' %s' % terms[ind])\n",
    "print(\"First method:\")\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f \"\n",
    "      % metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
    "\n",
    "#Note: You might see different results, as machine learning \n",
    "# algorithms do not produce the exact same results each time.\n",
    "#km.predict(X_test) to test our model\n",
    "\n",
    "#imports the KMeans algorithm from the scikit-learn library and \n",
    "# creates an instance of it with three clusters, a random state of 0, \n",
    "# and automatic initialization\n",
    "#KMeans algorithm is a clustering algorithm that groups \n",
    "# similar data points together based on their distance from each other\n",
    "kmeans = KMeans(n_clusters = 3, random_state = 0, n_init='auto')\n",
    "#The fit method is then called on the normalized training data \n",
    "# to train the KMeans model on the data.\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second method:\n",
      "Cluster 0:\n",
      " henry\n",
      " space\n",
      " toronto\n",
      " access\n",
      " nasa\n",
      " digex\n",
      " com\n",
      " pat\n",
      " zoo\n",
      " alaska\n",
      "Cluster 1:\n",
      " graphics\n",
      " space\n",
      " image\n",
      " com\n",
      " nasa\n",
      " university\n",
      " posting\n",
      " program\n",
      " host\n",
      " images\n",
      "Cluster 2:\n",
      " god\n",
      " people\n",
      " com\n",
      " jesus\n",
      " don\n",
      " say\n",
      " believe\n",
      " think\n",
      " bible\n",
      " just\n",
      "Cluster 3:\n",
      " sgi\n",
      " livesey\n",
      " keith\n",
      " solntze\n",
      " wpd\n",
      " jon\n",
      " com\n",
      " caltech\n",
      " morality\n",
      " moral\n",
      "Homogeneity: 0.558\n",
      "Completeness: 0.606\n",
      "V-measure: 0.581\n",
      "Adjusted Rand-Index: 0.555\n",
      "Silhouette Coefficient: 0.421 \n"
     ]
    }
   ],
   "source": [
    "print(\"Second method:\")\n",
    "original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "for i in range(true_k):\n",
    "   print(\"Cluster %d:\" % i)\n",
    "   for ind in order_centroids[i, :10]:\n",
    "      print(' %s' % terms[ind])\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f \"\n",
    "      % metrics.silhouette_score(X, km.labels_, sample_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset (file):\n",
    "    dataset = pd.read_csv(file)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data (dataset) :\n",
    "    print(dataset.head())\n",
    "    print (\"Nombre de lignes du dataset :\", dataset.shape[0])\n",
    "    print(\"Nombre de colonnes du dataset : \", dataset.shape[1])\n",
    "    print(\"Noms des colonnes : \", dataset.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset1 = load_dataset(\"Apple-Twitter-Sentiment-DFE.csv\")\n",
    "dataset2 = load_dataset(\"training.1600000.processed.noemoticon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
      "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
      "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
      "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
      "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
      "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
      "\n",
      "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
      "0  is upset that he can't update his Facebook by ...                                                                   \n",
      "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
      "2    my whole body feels itchy and like its on fire                                                                    \n",
      "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
      "4                      @Kwesidei not the whole crew                                                                    \n",
      "Nombre de lignes du dataset : 1599999\n",
      "Nombre de colonnes du dataset :  6\n",
      "Noms des colonnes :  ['0', '1467810369', 'Mon Apr 06 22:19:45 PDT 2009', 'NO_QUERY', '_TheSpecialOne_', \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"]\n"
     ]
    }
   ],
   "source": [
    "visualize_data(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599999 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
       "0        is upset that he can't update his Facebook by ...                                                                 \n",
       "1        @Kenichan I dived many times for the ball. Man...                                                                 \n",
       "2          my whole body feels itchy and like its on fire                                                                  \n",
       "3        @nationwideclass no, it's not behaving at all....                                                                 \n",
       "4                            @Kwesidei not the whole crew                                                                  \n",
       "...                                                    ...                                                                 \n",
       "1599994  Just woke up. Having no school is the best fee...                                                                 \n",
       "1599995  TheWDB.com - Very cool to hear old Walt interv...                                                                 \n",
       "1599996  Are you ready for your MoJo Makeover? Ask me f...                                                                 \n",
       "1599997  Happy 38th Birthday to my boo of alll time!!! ...                                                                 \n",
       "1599998  happy #charitytuesday @theNSPCC @SparksCharity...                                                                 \n",
       "\n",
       "[1599999 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2 = dataset2.iloc[:, -1:]\n",
    "dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Tweets\n",
      "0                                              Need a hug \n",
      "1        @LOLTrish hey  long time no see! Yes.. Rains a...\n",
      "2                     @Tatiana_K nope they didn't have it \n",
      "3                                @twittera que me muera ? \n",
      "4              spring break in plain city... it's snowing \n",
      "...                                                    ...\n",
      "1599989  Just woke up. Having no school is the best fee...\n",
      "1599990  TheWDB.com - Very cool to hear old Walt interv...\n",
      "1599991  Are you ready for your MoJo Makeover? Ask me f...\n",
      "1599992  Happy 38th Birthday to my boo of alll time!!! ...\n",
      "1599993  happy #charitytuesday @theNSPCC @SparksCharity...\n",
      "\n",
      "[1599994 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Personalized labels for columns\n",
    "personalized_labels = ['Tweets']\n",
    "\n",
    "# Assigning personalized labels to columns\n",
    "dataset2.columns = personalized_labels\n",
    "\n",
    "# Dropping the first row (as it's now the column names)\n",
    "dataset2 = dataset2.drop(0)\n",
    "\n",
    "# Resetting the index after dropping the first row\n",
    "dataset2 = dataset2.reset_index(drop=True)\n",
    "\n",
    "# Displaying the corrected DataFrame with personalized labels\n",
    "print(dataset2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
