{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Myriam Myriam nsubj saw\n",
      "Clement Clement dobj saw\n",
      "a telescope telescope pobj with\n",
      "Token: Myriam, Syntactic Head: saw\n",
      "Token: saw, Syntactic Head: saw\n",
      "Token: Clement, Syntactic Head: saw\n",
      "Token: with, Syntactic Head: saw\n",
      "Token: a, Syntactic Head: telescope\n",
      "Token: telescope, Syntactic Head: with\n",
      "Token: ., Syntactic Head: saw\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sent_0 = nlp(u'Myriam saw Clement with a telescope.')\n",
    "sent_1 = nlp(u'Self-driving cars shift insurance liability toward manufacturers.')\n",
    "sent_2 = nlp(u'I shot the elephant in my pyjamas.')\n",
    "for chunk in sent_0.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "    chunk.root.head.text)\n",
    "\n",
    "for token in sent_0:\n",
    "    print(f\"Token: {token.text}, Syntactic Head: {token.head.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_0 = nlp(u'Many people attended the event')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: Many, Syntactic Head: Many\n",
      "Token: people, Syntactic Head: people\n",
      "Token: attended, Syntactic Head: attended\n",
      "Token: the, Syntactic Head: the\n",
      "Token: event, Syntactic Head: event\n"
     ]
    }
   ],
   "source": [
    "for token in sent_0:\n",
    "    print(f\"Token: {token.text}, Syntactic Head: {token.head.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "import random \n",
    "\n",
    "TRAIN_DATA = [\n",
    "\n",
    "(\"There are a few apples in the basket\", { 'heads': [1, 1, 3, 4, 1, 4, 7,5],'deps': ['nsubj', 'ROOT', 'DET', 'QUANTITY', 'NOUN ', 'ADP',\n",
    "'DET','NOUN']}),\n",
    "\n",
    "]\n",
    "    # (\"Many people attended the event\", {\n",
    "    #     'deps': ['Quantity', '-', '-', '-', '-']\n",
    "    # }),\n",
    "    # (\"There are many books on the shelf\", {\n",
    "    #     'deps': ['-', '-', 'Quantity', '-', '-', '-', '-']\n",
    "    # }),\n",
    "    # (\"I have enough time to finish the task\", {\n",
    "    #     'deps': ['-', '-', 'Quantity', '-', '-', '-', '-', '-']\n",
    "    # }),\n",
    "    # (\"Some students passed the exam\", {\n",
    "    #     'deps': ['Quantity', '-', '-', '-', '-']\n",
    "    # }),\n",
    "    # (\"All employees attended the meeting\", {\n",
    "    #     'deps': ['Quantity', '-', '-', '-', '-']\n",
    "    # }),\n",
    "    # (\"Half of the pizza is gone\", {\n",
    "    #     'deps': ['Quantity', '-', '-', '-', '-', '-']\n",
    "    # }),\n",
    "    # (\"The whole team celebrated the victory\", {\n",
    "    #     'deps': ['-', 'Quantity', '-', '-', '-', '-']\n",
    "    # }),\n",
    "    # (\"There is enough food for everyone\", {\n",
    "    #     'deps': ['-', '-', 'Quantity', '-', '-', '-']\n",
    "    # }),\n",
    "    # (\"Numerous stars lit up the night sky\", {\n",
    "    #     'deps': ['Quantity', '-', '-', '-', '-', '-', '-']\n",
    "    # }),\n",
    "\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "if \"parser\" not in nlp.pipe_names:\n",
    "    parser = nlp.add_pipe(\"parser\")\n",
    "else:\n",
    "    parser = nlp.get_pipe(\"parser\")\n",
    "\n",
    "parser.add_label(\"Quantity\")\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for text, annotations in TRAIN_DATA:\n",
    "    tokens = nlp.make_doc(text)\n",
    "    deps = annotations['deps']\n",
    "    example = Example.from_dict(tokens, {\"deps\": deps})\n",
    "    training_data.append(example)\n",
    "\n",
    "\n",
    "random.shuffle(training_data)\n",
    "\n",
    "nlp.begin_training()\n",
    "for _ in range(25): \n",
    "    spacy.util.fix_random_seed(1)\n",
    "    for example in training_data:\n",
    "        nlp.update([example], drop=0.5)\n",
    "\n",
    "nlp.to_disk(\"custom_dependency_parser_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from custom_dependency_parser_model\n",
      "Some students passed the exam\n",
      "[('Some', 'ROOT'), ('students', 'ROOT'), ('passed', 'ROOT'), ('the', 'ROOT'), ('exam', 'ROOT')]\n",
      "find me the whole gym near work\n",
      "[('find', 'ROOT'), ('me', 'ROOT'), ('the', 'ROOT'), ('whole', 'ROOT'), ('gym', 'ROOT'), ('near', 'ROOT'), ('work', 'ROOT')]\n",
      "show me the enough hotel in berlin\n",
      "[('show', 'ROOT'), ('me', 'ROOT'), ('the', 'ROOT'), ('enough', 'ROOT'), ('hotel', 'ROOT'), ('in', 'ROOT'), ('berlin', 'ROOT')]\n"
     ]
    }
   ],
   "source": [
    "texts = [\"Some students passed the exam\",\n",
    "             \"find me the whole gym near work\",\n",
    "             \"show me the enough hotel in berlin\"]\n",
    "\n",
    "print(\"Loading from\", \"custom_dependency_parser_model\")\n",
    "nlp2 = spacy.load(\"custom_dependency_parser_model\")\n",
    "\n",
    "\n",
    "docs = nlp2.pipe(texts)\n",
    "for doc in docs:\n",
    "    print(doc.text)\n",
    "    print([(t.text, t.dep_) for t in doc if t.dep_ != '-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = [\n",
    "    (\"find a cafe with few wifi\", {\n",
    "        'heads': [0, 2, 0, 5, 5, 2],  # index of token head\n",
    "        'deps': ['ROOT', '-', 'PLACE', '-', 'Quantity', 'ATTRIBUTE']\n",
    "    }),\n",
    "    (\"find a hotel near the beach\", {\n",
    "        'heads': [0, 2, 0, 5, 5, 2],\n",
    "        'deps': ['ROOT', '-', 'PLACE', 'QUALITY', '-', 'ATTRIBUTE']\n",
    "    }),\n",
    "    (\"find me the enough gym that's open late\", {\n",
    "        'heads': [0, 0, 4, 4, 0, 6, 4, 6, 6],\n",
    "        'deps': ['ROOT', '-', '-', 'Quantity', 'PLACE', '-', '-', 'ATTRIBUTE', 'TIME']\n",
    "    }),\n",
    "    (\"show me the many stores that sell flowers\", {\n",
    "        'heads': [0, 0, 4, 4, 0, 4, 4, 4],  # attach \"flowers\" to store!\n",
    "        'deps': ['ROOT', '-', '-', 'Quantity', 'PLACE', '-', '-', 'PRODUCT']\n",
    "    }),\n",
    "    (\"find a whole restaurant in london\", {\n",
    "        'heads': [0, 3, 3, 0, 3, 3],\n",
    "        'deps': ['ROOT', '-', 'Quantity', 'PLACE', '-', 'LOCATION']\n",
    "    }),\n",
    "    (\"show me the all hostel in berlin\", {\n",
    "        'heads': [0, 0, 4, 4, 0, 4, 4],\n",
    "        'deps': ['ROOT', '-', '-', 'Quantity', 'PLACE', '-', 'LOCATION']\n",
    "    }),\n",
    "    (\"find a whole italian restaurant all work\", {\n",
    "        'heads': [0, 4, 4, 4, 0, 4, 5],\n",
    "        'deps': ['ROOT', '-', 'Quantity', 'ATTRIBUTE', 'PLACE', 'Quantity', 'LOCATION']\n",
    "    })\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA = [\n",
    "#     (\"There were few apples on the tree.\", {\n",
    "#         'heads': [2, 0, 5, 2, 5, 5, 2],\n",
    "#         'deps': ['-', 'Quantity', 'ATTRIBUTE', 'PLACE', 'PRODUCT', 'ATTRIBUTE', '-']\n",
    "#     }),\n",
    "    # (\"Many people attended the event.\", {\n",
    "    #     'heads': [2, 0, 4, 4, 4, 4],\n",
    "    #     'deps': ['-', 'Quantity', 'ATTRIBUTE', 'PLACE', 'EVENT', 'ATTRIBUTE']\n",
    "    # }),\n",
    "    # (\"I have enough time to finish the task.\", {\n",
    "    #     'heads': [1, 4, 7, 7, 7, 7, 7, 7],\n",
    "    #     'deps': ['-', 'Quantity', 'ATTRIBUTE', 'TIME', 'TASK', 'ATTRIBUTE', '-', '-']\n",
    "    # }),\n",
    "    # (\"Some students passed the exam.\", {\n",
    "    #     'heads': [2, 0, 5, 5, 5, 5],\n",
    "    #     'deps': ['-', 'Quantity', 'ATTRIBUTE', 'PLACE', 'EXAM', 'ATTRIBUTE']\n",
    "    # }),\n",
    "    # (\"All employees attended the meeting.\", {\n",
    "    #     'heads': [2, 0, 5, 5, 5, 5],\n",
    "    #     'deps': ['-', 'Quantity', 'ATTRIBUTE', 'PLACE', 'EVENT', 'ATTRIBUTE']\n",
    "    # }),\n",
    "    # (\"Half of the pizza is gone.\", {\n",
    "    #     'heads': [3, 0, 6, 6, 6, 6],\n",
    "        \n",
    "    #     'deps': ['-', 'Quantity', 'ATTRIBUTE', 'PRODUCT', 'ATTRIBUTE', '-']\n",
    "    # }),\n",
    "    # (\"The whole team celebrated the victory.\", {\n",
    "    #     'heads': [4, 0, 4, 4, 4, 4],\n",
    "    #     'deps': ['-', 'Quantity', 'ATTRIBUTE', 'PLACE', 'EVENT', 'ATTRIBUTE']\n",
    "    # }),\n",
    "    # (\"There is enough food for everyone.\", {\n",
    "    #     'heads': [2, 0, 5, 5, 5, 5, 8, 8, 8, 8, 8],\n",
    "#         'deps': ['-', 'Quantity', 'ATTRIBUTE', 'PLACE', 'PRODUCT', 'ATTRIBUTE', '-', 'GROUP', 'ATTRIBUTE', '-']\n",
    "#     }),\n",
    "#     (\"Numerous stars lit up the night sky.\", {\n",
    "#         'heads': [2, 0, 5, 5, 5, 5, 5],\n",
    "#         'deps': ['-', 'Quantity', 'ATTRIBUTE', 'PLACE', 'NIGHT', 'ATTRIBUTE', 'ATTRIBUTE']\n",
    "#     }),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "import random \n",
    "\n",
    "TRAIN_DATA = [\n",
    "    (\"find a cafe with great wifi\", {\n",
    "        'heads': [0, 2, 0, 5, 5, 2],  # index of token head\n",
    "        'deps': ['ROOT', '-', 'PLACE', '-', 'QUALITY', 'ATTRIBUTE']\n",
    "    }),\n",
    "    (\"find a hotel near the beach\", {\n",
    "        'heads': [0, 2, 0, 5, 5, 2],\n",
    "        'deps': ['ROOT', '-', 'PLACE', 'QUALITY', '-', 'ATTRIBUTE']\n",
    "    }),\n",
    "    (\"find me the closest gym that's open late\", {\n",
    "        'heads': [0, 0, 4, 4, 0, 6, 4, 6, 6],\n",
    "        'deps': ['ROOT', '-', '-', 'QUALITY', 'PLACE', '-', '-', 'ATTRIBUTE', 'TIME']\n",
    "    }),\n",
    "    (\"show me the cheapest store that sells flowers\", {\n",
    "        'heads': [0, 0, 4, 4, 0, 4, 4, 4],  # attach \"flowers\" to store!\n",
    "        'deps': ['ROOT', '-', '-', 'QUALITY', 'PLACE', '-', '-', 'PRODUCT']\n",
    "    }),\n",
    "    (\"find a nice restaurant in london\", {\n",
    "        'heads': [0, 3, 3, 0, 3, 3],\n",
    "        'deps': ['ROOT', '-', 'QUALITY', 'PLACE', '-', 'LOCATION']\n",
    "    }),\n",
    "    (\"show me the coolest hostel in berlin\", {\n",
    "        'heads': [0, 0, 4, 4, 0, 4, 4],\n",
    "        'deps': ['ROOT', '-', '-', 'QUALITY', 'PLACE', '-', 'LOCATION']\n",
    "    }),\n",
    "    (\"find a good italian restaurant near work\", {\n",
    "        'heads': [0, 4, 4, 4, 0, 4, 5],\n",
    "        'deps': ['ROOT', '-', 'QUALITY', 'ATTRIBUTE', 'PLACE', 'ATTRIBUTE', 'LOCATION']\n",
    "    })\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "if \"parser\" not in nlp.pipe_names:\n",
    "    parser = nlp.add_pipe(\"parser\")\n",
    "else:\n",
    "    parser = nlp.get_pipe(\"parser\")\n",
    "\n",
    "parser.add_label(\"QUALITY\")\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for text, annotations in TRAIN_DATA:\n",
    "    tokens = nlp.make_doc(text)\n",
    "    deps = annotations['deps']\n",
    "    example = Example.from_dict(tokens, {\"deps\": deps})\n",
    "    training_data.append(example)\n",
    "\n",
    "\n",
    "random.shuffle(training_data)\n",
    "\n",
    "nlp.begin_training()\n",
    "for _ in range(25): \n",
    "    spacy.util.fix_random_seed(1)\n",
    "    for example in training_data:\n",
    "        nlp.update([example], drop=0.5)\n",
    "\n",
    "nlp.to_disk(\"custom_dependency_parser_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from custom_dependency_parser_model\n",
      "find a hotel with good wifi\n",
      "[]\n",
      "find me the cheapest gym near work\n",
      "[]\n",
      "show me the best hotel in berlin\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Loading from\", \"custom_dependency_parser_model\")\n",
    "nlp2 = spacy.load(\"custom_dependency_parser_model\")\n",
    "\n",
    "\n",
    "texts = [\"find a hotel with good wifi\",\n",
    "         \"find me the cheapest gym near work\",\n",
    "         \"show me the best hotel in berlin\"]\n",
    "\n",
    "docs = nlp.pipe(texts)\n",
    "for doc in docs:\n",
    "    print(doc.text)\n",
    "    print([(t.text, t.dep_, t.head.text) for t in doc if t.dep_ != 'ROOT'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
